# 1 卷积

卷积神经网络中的卷积是什么含义？

1. 数学：一个系统有不稳定的输入但是有稳定的输出，我们可以通过卷积来计算系统存量

1. 图像处理：一个卷积核规定了周围像素点对当前像素点产生的影响

1. 过滤器：一个像素点会如何试探周围的像素点

# 2 感知机

无法进行亦或的逻辑运算，计算能力不如图灵机，那么更加不如人脑。

一个分类的模板——线性函数+激活函数

本质是“分治”思想



改进：变形/升维

# 3 神经网络

输入层->隐藏层（我们不知道）->输出层

```text
全神经网络
前馈神经网络
循环神经网络（RNN）
```

激活函数从0-1越阶函数变成了sigmoid函数

- ReLU陡峭的变化 甚至没有上线

- sigmoid渐进的变化

- 0-1越阶函数阶梯变化

***

> **机器学习为什么又叫统计学习？**

> 因为卷积神经网络算法的结果可以逼近任何一个统计规律

***

> **为什么最优策略无法被归约？但是现实中的物理规律可以被统一表示呢？**

> 因为策略是进化、演化的产物，需要优胜略汰，存在生存和毁灭的价值判断；而物理规律是底层规律的组合，没有发生演化。

> 例如，物理规律中只会包含狸花猫，橘猫之类的，但是在演化过程中还出现了叮当猫，而叮当猫必须要经过学习才能识别。

***

# 4 损失函数

梯度下降法是训练神经网络的基本方法，而求的梯度就是损失函数的梯度。

***

损失函数的三种计算方法：

1.最小二乘法（最白给的方法，但是它在梯度下降的时候会很麻烦）



2.极大似然估计（概率的反向运用）

> 从真实世界反推，真实的情况已经发生，在当前模型下发生这个情况的可能性。

> 挑出似然值最大的模型，这个模型与现实相符的概率也就最高。

have something to write



3.交叉熵法

***

> 斯图尔特曾经说过一句话：色情是什么我不知道，但是只要你拿给我看，我就能判断出来。

定义：神经网络的标准和你心中的标准相差多少的定量表达。

# 5 交叉熵

概率系统P



**相对熵**，又叫**KL散度**



